{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#1.Déscription briève du dataset Iris\n",
    "\"\"\"\n",
    "Origine : Il a été introduit par le statisticien Ronald A. Fisher en 1936 pour illustrer des techniques de classification.\n",
    "Variables :\n",
    "    Caractéristiques : sepal length, sepal width, petal length, petal width.\n",
    "    Classe cible : Trois espèces de fleurs (setosa, versicolor, virginica).\n",
    "Objectif d’étude : Classifier les espèces de fleurs en fonction des caractéristiques mesurées.\n",
    "\"\"\"\n",
    "\n",
    "#2. Créer des visualisations pertinentes :\n",
    "\n",
    "    #1. Importez les bibliothèques nécessaires :\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "    #2. Chargez le dataset :\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['species'] = iris.target\n",
    "species_names = iris.target_names\n",
    "data['species'] = data['species'].map({0: species_names[0], 1: species_names[1], 2: species_names[2]})\n",
    "\n",
    "    #3. Visualisations recommandées\n",
    "sns.pairplot(data, hue=\"species\", diag_kind=\"kde\")\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(data.iloc[:, :-1].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#3. Observations importantes\n",
    "\"\"\"\n",
    "1. Séparation des espèces\n",
    "Les espèces Setosa, Versicolor, et Virginica sont bien séparées dans plusieurs dimensions.\n",
    "La Setosa est particulièrement distincte des deux autres espèces, \n",
    "surtout en fonction des caractéristiques petal length (cm) et petal width (cm).\n",
    "Les espèces Versicolor et Virginica se chevauchent légèrement, \n",
    "ce qui pourrait poser des défis pour certains modèles de classification.\n",
    "\n",
    "2. Importance des variables pour la séparation\n",
    "Petal length (cm) et Petal width (cm) semblent être les caractéristiques les plus discriminantes pour différencier les espèces,\n",
    "car elles montrent des regroupements nets.\n",
    "Les variables Sepal length (cm) et Sepal width (cm) ont une plus grande superposition entre les espèces,\n",
    "ce qui les rend moins discriminantes.\n",
    "\n",
    "3. Relation entre les variables\n",
    "Une corrélation positive est visible entre petal length (cm) et petal width (cm) : à mesure que la longueur des pétales augmente, \n",
    "leur largeur augmente également.\n",
    "Les variables sepal length (cm) et sepal width (cm) semblent moins fortement corrélées, \n",
    "mais elles montrent également des relations linéaires légères.\n",
    "\n",
    "4. Distribution des variables\n",
    "Les distributions des caractéristiques diffèrent selon les espèces :\n",
    "Les longueurs et largeurs des pétales pour Setosa sont significativement plus petites que celles des autres espèces.\n",
    "Virginica a généralement les plus grandes valeurs pour petal length (cm) et petal width (cm).\n",
    "\n",
    "5. Séparation intra-espèce\n",
    "Bien que les espèces soient globalement bien séparées, les points verts (Virginica) et points orange (Versicolor) \n",
    "montrent une certaine proximité dans les graphiques, notamment dans sepal dimensions, ce qui indique que ces caractéristiques \n",
    "pourraient ne pas suffire pour une classification fiable seule.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Afficher les premières lignes pour validation\n",
    "print(data.head())\n",
    "\n",
    "# Séparer les données en variables explicatives (X) et cible (y)\n",
    "X = data[iris.feature_names]\n",
    "y = data['species']\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# 4a. Modèle de régression logistique\n",
    "print(\"\\n=== Régression logistique ===\")\n",
    "logistic_model = LogisticRegression(max_iter=200)  # Initialiser le modèle\n",
    "logistic_model.fit(X_train, y_train)  # Entraîner le modèle\n",
    "\n",
    "# Prédire sur les données de test\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Précision : {accuracy_logistic:.2f}\")\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "\n",
    "\n",
    "\n",
    "# 4b. Modèle KNN avec choix du meilleur k\n",
    "print(\"\\n=== KNN ===\")\n",
    "k_values = range(1, 21)  # Tester k de 1 à 20\n",
    "accuracies = []\n",
    "\n",
    "# Tester différents k pour trouver le meilleur\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred_knn = knn_model.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_knn))\n",
    "\n",
    "# Trouver le k optimal\n",
    "best_k = k_values[accuracies.index(max(accuracies))]\n",
    "print(f\"Meilleur k : {best_k}, Précision maximale : {max(accuracies):.2f}\")\n",
    "\n",
    "# Entraîner le modèle final avec le meilleur k\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#5. Évaluer les performances\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Comparaison des modèles\n",
    "print(\"\\n=== Comparaison des modèles ===\")\n",
    "print(f\"Précision Régression Logistique : {accuracy_logistic:.2f}\")\n",
    "print(f\"Précision KNN (k={best_k}) : {max(accuracies):.2f}\")\n",
    "\n",
    "# Tester quelle précision est la plus élevée et afficher le modèle le plus performant\n",
    "if accuracy_logistic > max(accuracies):\n",
    "    best_model = \"Régression Logistique\"\n",
    "    best_accuracy = accuracy_logistic\n",
    "else:\n",
    "    best_model = f\"KNN (k={best_k})\"\n",
    "    best_accuracy = max(accuracies)\n",
    "\n",
    "print(f\"\\nLe modèle le plus performant est : {best_model} avec une précision de {best_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
